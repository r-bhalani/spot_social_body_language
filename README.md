# Spot Making Social Body Language

<img src="https://d33wubrfki0l68.cloudfront.net/dd322f87de0e52e2cf381e96d4392b135b6dca61/8fd3c/_images/spotframes.png" width="300">

This project presents a development process to improve upon the basic building-blocks of Boston Dynamics's quadruped robot Spot navigation behaviors to produce behaviors that are more dog-like in appearance. 

The process begins with the distribution of an open-ended survey which asks study participants what behaviors the robot could perform to look more dog-like. From these survey responses, a set of behaviors are chosen for development on the Spot: tail wag, play bow, sit, walk in circle, and spin, as well as matters of smoother movement and varying walking speed. Each of the chosen behaviors is hand-coded as a motion defined through a set of trajectory points that the robot follows, approximating the behavior of a real dog, and then the behaviors are compiled into "canine" and "non-canine" montages, which are performed by the robot in a busy public space on the UT Austin campus. 

Nearby pedestrians are able to log into an online survey using a QR code to provide their impressions of the robot, rating its behavior on a modified version of the Godspeed Questionnaire. The results of the study show that participants find the robot to be more dog-like, and that they rated it more positively on several other measures, when the robot is running the "canine" montage, finding it to be more conscious, responsive, friendly, interactive, and lifelike. These results can be used to develop more socially-engaging software architectures for the Spot and other quadruped robots.

[**Winner of CNS Award for Excellence in Computer Science and Computer Engineering at 2022 UT Austin Undergraduate Research Forum**](https://cns.utexas.edu/tides/undergraduate/undergraduate-research-forum/awards-honors)

**Submitted to 31st IEEE International Conference on Robot & Human Interactive Communication**

[URF Poster Presentation](https://airtable.com/shrZsf4TrtxkhNjdK/tbla1OFoYYmKZqOAW/viwz3jLFBDBuN9kb4/recLgqh8tXXw21EAT/fldVUgrgViRCaeOmc/attVva23KNjNylmKT)

[Conference Presentation](
https://docs.google.com/presentation/d/1DMjsoGu7AeB01ksL1d4BbpiFfofgNHopHR6yB1G53lk/edit?usp=sharing)

[Research Paper](https://github.com/r-bhalani/spot_social_body_language/blob/dd0333d2f3c3bf1ca755b61ba567a4808f391722/Spot%20Making%20Social%20Body%20Language.pdf)

UT Austin Learning Agents Research Group, AI Lab

